# 프로젝트 개요
소셜 네트워크 서비스 서비스

## API 연동 및 데이터 획득

### 사용자 조회
- **기능**: 특정 사용자 ID를 기반으로 전반적인 정보 조회를 합니다.

#### 2. 요청(Request)
- **HTTP Method**: `GET`
- **Endpoint**: `/api/v1/users/`

#### 요청 파라미터
userId: String

#### 요청 예시
GET /api/v1/users/123/

#### 요청 응답
```json
{
  "userId": "123",
  "postCount": 456,
  "follwers": 7203,
  "follwings": 1,
  "likes": 6885
}
```

### 사용자 활동 데이터 조회
- **기능**: 특정 사용자 ID를 기반으로 페이징 처리 하여 사용자 활동 데이터 조회

#### 2. 요청(Request)
- **HTTP Method**: `GET`
- **Endpoint**: `/api/v1/users/123/actions`

#### 요청 파라미터
userId: String
page: Int

#### 요청 예시
GET /api/v1/users/123/actions&page=1

#### 요청 응답
```json
```json
{
  "userId": "123",
  "actions": [
    {
      "action": "POST_LIKE",
      "userId": "768" 
    },
    {
      "action": "USER_FOLLOW",
      "userId": "1523" 
    },
    {
      "action": "USER_FOLLOWING",
      "userId": "12111" 
    },
  ],
  "page": 1,
  "isEnd": false
}
```

## 데이터 표현 및 저장 전략

### 데이터 저장
- Redis -> Mysql로 저장하여 실시간 조회는 모두 Redis로 진행
- Redis와 Database에 write 하도록 하고, history 와 관련된 데이터틑 큐를 이용하여 저장
- Redis 저장 후 Database write는 이벤트 발행이나 큐를 사용 하도록 함

### 조회 성능
- Redis 캐싱을 통해 Database Read를 사용하지 않게 됨
- Redis 키가 없는 경우 Database를 조회하고 해당 데이터를 캐싱 하도록 함
- 검색 빈도가 높거나 자주 노출되는 게시글을 별도로 조회 하도록 배치를 실행
- top 100 명의 데이터를 배치를 이용하여 메시지발행해 로컬 캐시에 적재하도록 함

## 실시간 데이터 처리 및 최적화

### 대규모 데이터 처리
- 배치를 통하여 이벤트 로그를 수집하여 저장하는 등의 배치가 필요
- Database 말고 다른 로그를 위한 데이터 저장소를 별도로 두는 것이 필요 (S3, Bigquery 등)
